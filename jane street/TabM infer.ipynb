{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":10253875,"sourceType":"datasetVersion","datasetId":6297065},{"sourceId":204479873,"sourceType":"kernelVersion"},{"sourceId":207787842,"sourceType":"kernelVersion"},{"sourceId":213144305,"sourceType":"kernelVersion"},{"sourceId":214892435,"sourceType":"kernelVersion"},{"sourceId":215017949,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rtdl_num_embeddings -q --no-index --find-links=/kaggle/input/jane-street-import/rtdl_num_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:13.407877Z","iopub.execute_input":"2024-12-28T02:20:13.408254Z","iopub.status.idle":"2024-12-28T02:20:22.067430Z","shell.execute_reply.started":"2024-12-28T02:20:13.408222Z","shell.execute_reply":"2024-12-28T02:20:22.066382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import r2_score\nimport pandas as pd\nimport math\nimport numpy as np\nfrom tqdm import tqdm\nimport polars as pl\nfrom collections import OrderedDict\nimport sys\nfrom tanm_reference import Model, make_parameter_groups\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport kaggle_evaluation.jane_street_inference_server\n\nimport os\n\nimport joblib\n\nfrom pytorch_lightning import LightningModule","metadata":{"_uuid":"f573766f-0a4b-4a41-a873-d3e78e56afaf","_cell_guid":"8936e699-b090-4d2b-9bf2-b77f90fbefdb","trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.069503Z","iopub.execute_input":"2024-12-28T02:20:22.069865Z","iopub.status.idle":"2024-12-28T02:20:22.076376Z","shell.execute_reply.started":"2024-12-28T02:20:22.069833Z","shell.execute_reply":"2024-12-28T02:20:22.075492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\nfeature_list = [f\"feature_{idx:02d}\" for idx in range(79)]\n\ntarget_col = \"responder_6\" \n\nfeature_test = feature_list \\\n                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n\nfeature_cat = [\"feature_09\", \"feature_10\", \"feature_11\" , 'symbol_id']\nfeature_cont = [item for item in feature_test if item not in feature_cat]\n\nbatch_size = 8192\n\nstd_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n\ndata_stats = joblib.load(\"/kaggle/input/my-own-js/data_stats.pkl\")\nmeans = data_stats['mean']\nstds = data_stats['std']\n\ndef standardize(df, feature_cols, means, stds):\n    return df.with_columns([\n        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.077646Z","iopub.execute_input":"2024-12-28T02:20:22.077908Z","iopub.status.idle":"2024-12-28T02:20:22.098133Z","shell.execute_reply.started":"2024-12-28T02:20:22.077883Z","shell.execute_reply":"2024-12-28T02:20:22.097367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n 'time_id' : {i : i for i in range(968)}}\n\ndef encode_column(df, column, mapping):\n    max_value = max(mapping.values())  \n\n    def encode_category(category):\n        return mapping.get(category, max_value + 1)  \n    \n    return df.with_columns(\n        pl.col(column).map_elements(encode_category).alias(column)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.099982Z","iopub.execute_input":"2024-12-28T02:20:22.100273Z","iopub.status.idle":"2024-12-28T02:20:22.110230Z","shell.execute_reply.started":"2024-12-28T02:20:22.100246Z","shell.execute_reply":"2024-12-28T02:20:22.109324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TabM","metadata":{}},{"cell_type":"code","source":"class R2Loss(nn.Module):\n    def __init__(self):\n        super(R2Loss, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        mse_loss = torch.sum((y_pred - y_true) ** 2)\n        var_y = torch.sum(y_true ** 2)\n        loss = mse_loss / (var_y + 1e-38)\n        return loss\n\nclass NN(LightningModule):\n    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n        super().__init__()\n        self.save_hyperparameters()\n        self.k = 16\n        self.model = Model(\n                n_num_features=n_cont_features,\n                cat_cardinalities=cat_cardinalities,\n                n_classes=n_classes,\n                backbone={\n                    'type': 'MLP',\n                    'n_blocks': 3 ,\n                    'd_block': 256,\n                    'dropout': 0.15,\n                },\n                bins=None,\n                num_embeddings= None,\n                arch_type='tabm',\n                k=self.k,\n            )\n        self.lr = lr\n        self.weight_decay = weight_decay\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        self.loss_fn = R2Loss()\n        # self.loss_fn = weighted_mse_loss\n\n    def forward(self, x_cont, x_cat):\n        return self.model(x_cont, x_cat).squeeze(-1)\n\n    def training_step(self, batch):\n        x_cont,x_cat, y, w , w_y= batch\n        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.training_step_outputs.append((y_hat.mean(1), y, w))\n        return loss\n\n    def validation_step(self, batch):\n        x_cont,x_cat, y, w, w_y = batch\n        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n        return loss\n\n    def on_validation_epoch_end(self):\n        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n        if self.trainer.sanity_checking:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n        else:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n            # r2_val\n            val_r_square = r2_val(y, prob, weights)\n            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.validation_step_outputs.clear()\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n        #                                                        verbose=True)\n        return {\n            'optimizer': optimizer,\n            # 'lr_scheduler': {\n            #     'scheduler': scheduler,\n            #     'monitor': 'val_r_square',\n            # }\n        }\n\n    def on_train_epoch_end(self):\n        if self.trainer.sanity_checking:\n            return\n\n        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n        # r2_training\n        train_r_square = r2_val(y, prob, weights)\n        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.training_step_outputs.clear()\n\n        epoch = self.trainer.current_epoch\n        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n        print(f\"Epoch {epoch}: {formatted_metrics}\")\n        \n# class custom_args():\n#     def __init__(self):\n#         self.usegpu = True\n#         self.gpuid = 0\n#         self.seed = 42\n#         self.model = 'nn'\n#         self.use_wandb = False\n#         self.project = 'js-tabm-with-lags'\n#         self.dname = \"./input_df/\"\n#         self.loader_workers = 10   \n#         self.bs = 8192\n#         self.lr = 1e-3\n#         self.weight_decay = 8e-4\n#         self.n_cont_features = 84\n#         self.n_cat_features = 5\n#         self.n_classes = None\n#         self.cat_cardinalities = [23, 10, 32, 40, 969]\n#         self.patience = 7\n#         self.max_epochs = 10\n#         self.N_fold = 5\n\n\n# my_args = custom_args()\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# model = NN.load_from_checkpoint('/kaggle/input/my-own-js/tabm_epochepoch03.ckpt').to(device)\n# model = NN.load_from_checkpoint('/kaggle/input/jane-street-tabm-ft-transformer-training/epoch2_r2_0.008409321308135986.pt').to(device)\n\n\nn_cont_features = 85\n# n_cont_features = 89\nn_cat_features = 4\nn_classes = None\n# cat_cardinalities = [83, 13, 540, 40]\ncat_cardinalities = [23, 10, 32, 40]\narch_type = 'tabm'\nbins = None\nk = 16\n\nmodel = Model(\n    n_num_features=n_cont_features,\n    cat_cardinalities=cat_cardinalities,\n    n_classes=n_classes,\n    backbone={\n        'type': 'MLP',\n        'n_blocks': 3 ,\n        'd_block': 256,\n        'dropout': 0.15,\n    },\n    bins=bins,\n    # num_embeddings=(\n    #     None\n    #     if bins is None\n    #     else {\n    #         'type': 'PiecewiseLinearEmbeddings',\n    #         'd_embedding': 16,\n    #         'activation': True,\n    #         'version': 'B',\n    #     }\n    # ),\n    num_embeddings=(\n        None\n        # {\n        #     'type': 'PeriodicEmbeddings',\n        #     'd_embedding': 16,\n        #     'lite':True,\n        # }\n    ),\n    arch_type=arch_type,\n    k=k,\n)\n\nstate_dict = torch.load('/kaggle/input/jane-street-tabm-ft-transformer-training/epoch2_r2_0.008409321308135986.pt')['model_state_dict']\nmodel.load_state_dict(state_dict)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.111552Z","iopub.execute_input":"2024-12-28T02:20:22.111862Z","iopub.status.idle":"2024-12-28T02:20:22.160100Z","shell.execute_reply.started":"2024-12-28T02:20:22.111835Z","shell.execute_reply":"2024-12-28T02:20:22.159049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\nlags_last : pl.DataFrame | None = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    global lags_\n    global lags_last\n\n    if lags is not None:\n        lags_ = lags\n    \n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n    \n    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n    \n    for col in feature_cat:\n        test = encode_column(test, col, category_mappings[col])\n\n    time_id = test.select(\"time_id\").to_numpy()[0]\n    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n    \n    \n    if lags is not None:\n        lags_ = lags\n        lags_last = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n    \n    id_column_types = {\n        'date_id': pl.Int32,\n        'time_id': pl.Int32,\n        'symbol_id': pl.Int32\n    }\n    test = test.cast(id_column_types)\n    lags_last = lags_last.cast(id_column_types)\n\n    test = test.join(lags_last, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n\n    test = standardize(test, std_feature, means, stds)\n\n    test = test.with_columns([\n        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n    ])\n\n\n    X_test = test[feature_test].to_numpy()\n    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n    X_cat = X_test_tensor[:, [9, 10, 11]]\n    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n    # X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n    model.eval()\n    with torch.no_grad():\n        outputs = model(X_cont, X_cat)\n        # Assuming the model outputs a tensor of shape (batch_size, 1)\n        preds = outputs.squeeze(-1).cpu().numpy()\n        preds = preds.mean(1)\n    \n    predictions = \\\n    test.select('row_id').\\\n    with_columns(\n        pl.Series(\n            name   = 'responder_6', \n            values = np.clip(preds, a_min = -5, a_max = 5),\n            dtype  = pl.Float64,\n        )\n    )\n\n\n    # The predict function must return a DataFrame\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    # with columns 'row_id', 'responer_6'\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    # and as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.161649Z","iopub.execute_input":"2024-12-28T02:20:22.162248Z","iopub.status.idle":"2024-12-28T02:20:22.176471Z","shell.execute_reply.started":"2024-12-28T02:20:22.162203Z","shell.execute_reply":"2024-12-28T02:20:22.175358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nEVAL = False\nif EVAL:\n    test_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet'\n    lags_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet'\nelse:\n    test_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet'\n    lags_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet'\n\ninference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            test_dir,\n            lags_dir\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.178074Z","iopub.execute_input":"2024-12-28T02:20:22.178485Z","iopub.status.idle":"2024-12-28T02:20:22.238341Z","shell.execute_reply.started":"2024-12-28T02:20:22.178432Z","shell.execute_reply":"2024-12-28T02:20:22.237517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def weighted_zero_mean_r2(y_true, y_pred, weights):\n    \"\"\"\n    Calculate the sample weighted zero-mean R-squared score.\n\n    Parameters:\n    y_true (numpy.ndarray): Ground-truth values for responder_6.\n    y_pred (numpy.ndarray): Predicted values for responder_6.\n    weights (numpy.ndarray): Sample weight vector.\n\n    Returns:\n    float: The weighted zero-mean R-squared score.\n    \"\"\"\n    numerator = np.sum(weights * (y_true - y_pred)**2)\n    denominator = np.sum(weights * y_true**2)\n    \n    r2_score = 1 - numerator / denominator\n    return r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.239719Z","iopub.execute_input":"2024-12-28T02:20:22.240382Z","iopub.status.idle":"2024-12-28T02:20:22.245148Z","shell.execute_reply.started":"2024-12-28T02:20:22.240340Z","shell.execute_reply":"2024-12-28T02:20:22.244279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if EVAL:\n\n    submission_file = pd.read_parquet('/kaggle/working/submission.parquet')\n    y_pred = submission_file['responder_6']\n    \n    valid_df = pl.read_parquet(\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/valid_df.parquet\")\n    \n    y_true = valid_df.select(\"responder_6\").to_numpy().reshape(-1)\n    \n    weights = valid_df.select(\"weight\").to_numpy().reshape(-1)\n    \n    print(weighted_zero_mean_r2(y_true, y_pred, weights))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T02:20:22.246153Z","iopub.execute_input":"2024-12-28T02:20:22.246419Z","iopub.status.idle":"2024-12-28T02:20:22.258776Z","shell.execute_reply.started":"2024-12-28T02:20:22.246395Z","shell.execute_reply":"2024-12-28T02:20:22.257957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
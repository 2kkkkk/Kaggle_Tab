{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":10253875,"sourceType":"datasetVersion","datasetId":6297065},{"sourceId":203900450,"sourceType":"kernelVersion"},{"sourceId":207787842,"sourceType":"kernelVersion"},{"sourceId":214892435,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install rtdl_num_embeddings delu rtdl_revisiting_models ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:38.669387Z","iopub.execute_input":"2024-12-30T07:17:38.669709Z","iopub.status.idle":"2024-12-30T07:17:48.558274Z","shell.execute_reply.started":"2024-12-30T07:17:38.669668Z","shell.execute_reply":"2024-12-30T07:17:48.557100Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nimport rtdl_num_embeddings\nfrom rtdl_num_embeddings import compute_bins\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import r2_score\nimport pandas as pd\nimport math\nimport numpy as np\nimport delu\nfrom tqdm import tqdm\nimport polars as pl\nfrom collections import OrderedDict\nimport sys\n\nfrom tanm_reference import Model, make_parameter_groups\n\n\nfrom torch import Tensor\nfrom typing import List, Callable, Union, Any, TypeVar, Tuple\n\nimport joblib\n\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:48.560443Z","iopub.execute_input":"2024-12-30T07:17:48.560743Z","iopub.status.idle":"2024-12-30T07:17:52.699740Z","shell.execute_reply.started":"2024-12-30T07:17:48.560715Z","shell.execute_reply":"2024-12-30T07:17:52.699050Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nfeature_train_list = [f\"feature_{idx:02d}\" for idx in range(79)] \n\n\ntarget_col = \"responder_6\"\n\nfeature_train = feature_train_list \\\n                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n\nstart_dt = 1100\nend_dt = 1599\n\nfeature_cat = [\"feature_09\", \"feature_10\", \"feature_11\" , 'symbol_id']\nfeature_cont = [item for item in feature_train if item not in feature_cat]\nstd_feature = [i for i in feature_train_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n\n# batch_size = 2048\nbatch_size = 8192\nnum_epochs = 30\n\n\n# data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\ndata_stats = joblib.load('/kaggle/input/my-own-js/data_stats.pkl')\nmeans = data_stats['mean']\nstds = data_stats['std']\n\ndef standardize(df, feature_cols, means, stds):\n    return df.with_columns([\n        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.700945Z","iopub.execute_input":"2024-12-30T07:17:52.701465Z","iopub.status.idle":"2024-12-30T07:17:52.743931Z","shell.execute_reply.started":"2024-12-30T07:17:52.701426Z","shell.execute_reply":"2024-12-30T07:17:52.742973Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"motono0223_train_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/training.parquet\")\nmotono0223_valid_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet\")\nmotono0223_original = pl.concat([motono0223_train_original,motono0223_valid_original])\n\ntrain_original = motono0223_original.filter((pl.col(\"date_id\") >= start_dt) & (pl.col(\"date_id\") <= end_dt))\nvalid_original = motono0223_original.filter(pl.col(\"date_id\") > end_dt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.744891Z","iopub.execute_input":"2024-12-30T07:17:52.745149Z","iopub.status.idle":"2024-12-30T07:17:52.779130Z","shell.execute_reply.started":"2024-12-30T07:17:52.745124Z","shell.execute_reply":"2024-12-30T07:17:52.778429Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# train_original = pl.scan_parquet(\"/kaggle/input/jane-street-data-preprocessing/training.parquet\")\n# valid_original = pl.scan_parquet(\"/kaggle/input/jane-street-data-preprocessing/validation.parquet\")\n\n# def get_category_mapping(df, column):\n#     unique_values = df.select([column]).unique().collect().to_series()\n#     return {cat: idx for idx, cat in enumerate(unique_values)}\n\n# category_mappings = {col: get_category_mapping(all_original, col) for col in feature_cat + ['symbol_id']}\n\ncategory_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n 'time_id' : {i : i for i in range(968)}}\n\n\ndef encode_column(df, column, mapping):\n    def encode_category(category):\n        return mapping.get(category, -1)  \n    \n    return df.with_columns(\n        pl.col(column).map_elements(encode_category, return_dtype=pl.Int16).alias(column)\n    )\n\nfor col in feature_cat:\n    train_original = encode_column(train_original, col, category_mappings[col])\n    valid_original = encode_column(valid_original, col, category_mappings[col])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.780264Z","iopub.execute_input":"2024-12-30T07:17:52.780557Z","iopub.status.idle":"2024-12-30T07:17:52.796350Z","shell.execute_reply.started":"2024-12-30T07:17:52.780509Z","shell.execute_reply":"2024-12-30T07:17:52.795634Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_original = standardize(train_original, std_feature, means, stds)\nvalid_original = standardize(valid_original, std_feature, means, stds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.797300Z","iopub.execute_input":"2024-12-30T07:17:52.797539Z","iopub.status.idle":"2024-12-30T07:17:52.806345Z","shell.execute_reply.started":"2024-12-30T07:17:52.797501Z","shell.execute_reply":"2024-12-30T07:17:52.805463Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# train_data = train_original \\\n#              .filter((pl.col(\"date_id\") >= start_dt) & (pl.col(\"date_id\") <= end_dt)) \\\n#             .sort(['date_id', 'time_id']) \\\n#              .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n\ntrain_data = train_original.filter(pl.col(\"date_id\").ge(start_dt))\\\n                            .filter(pl.col(\"date_id\").le(end_dt))\\\n                            # .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n\nvalid_data = valid_original \\\n             .filter(pl.col(\"date_id\") > end_dt)\\\n             .sort(['date_id', 'time_id'])\\\n             # .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.808560Z","iopub.execute_input":"2024-12-30T07:17:52.808832Z","iopub.status.idle":"2024-12-30T07:17:52.817017Z","shell.execute_reply.started":"2024-12-30T07:17:52.808808Z","shell.execute_reply":"2024-12-30T07:17:52.816211Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_numpy = train_data.collect().to_pandas()[feature_train + [target_col, 'weight', 'symbol_id', 'time_id']].values\nvalid_numpy = valid_data.collect().to_pandas()[feature_train + [target_col, 'weight', 'symbol_id', 'time_id']].values\ntrain_numpy.shape,valid_numpy.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:17:52.817958Z","iopub.execute_input":"2024-12-30T07:17:52.818296Z","iopub.status.idle":"2024-12-30T07:18:57.565700Z","shell.execute_reply.started":"2024-12-30T07:17:52.818259Z","shell.execute_reply":"2024-12-30T07:18:57.564699Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((18424912, 92), (3679368, 92))"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"pd.set_option('display.max_columns',100)\nnan_stats = pd.DataFrame(np.isnan(train_numpy).sum(axis=0)/len(train_numpy)).T\nnan_stats.columns=[feature_train + [target_col, 'weight', 'symbol_id', 'time_id']]\nnan_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:18:57.566743Z","iopub.execute_input":"2024-12-30T07:18:57.567065Z","iopub.status.idle":"2024-12-30T07:18:59.533458Z","shell.execute_reply.started":"2024-12-30T07:18:57.567020Z","shell.execute_reply":"2024-12-30T07:18:59.532552Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  feature_00 feature_01 feature_02 feature_03 feature_04 feature_05  \\\n0        0.0        0.0        0.0        0.0        0.0        0.0   \n\n  feature_06 feature_07 feature_08 feature_09 feature_10 feature_11  \\\n0        0.0        0.0   0.013187        0.0        0.0        0.0   \n\n  feature_12 feature_13 feature_14 feature_15    feature_16 feature_17  \\\n0        0.0        0.0        0.0   0.024793  5.427434e-08   0.004132   \n\n  feature_18 feature_19 feature_20 feature_21 feature_22 feature_23  \\\n0        0.0        0.0        0.0   0.001576        0.0        0.0   \n\n  feature_24 feature_25 feature_26 feature_27 feature_28 feature_29  \\\n0        0.0        0.0   0.001576   0.001576        0.0        0.0   \n\n  feature_30 feature_31 feature_32 feature_33 feature_34 feature_35  \\\n0        0.0   0.001576   0.009858   0.009858        0.0        0.0   \n\n  feature_36 feature_37 feature_38 feature_39    feature_40 feature_41  \\\n0        0.0        0.0        0.0   0.070248  2.170974e-07   0.018595   \n\n  feature_42    feature_43 feature_44 feature_45 feature_46 feature_47  \\\n0   0.070248  2.170974e-07   0.018595   0.000148   0.000148        0.0   \n\n  feature_48 feature_49 feature_50 feature_51 feature_52 feature_53  \\\n0        0.0        0.0   0.070248        0.0   0.018595   0.070248   \n\n  feature_54 feature_55 feature_56 feature_57 feature_58 feature_59  \\\n0        0.0   0.018595        0.0        0.0   0.009858        0.0   \n\n  feature_60 feature_61 feature_62 feature_63 feature_64 feature_65  \\\n0        0.0        0.0    0.00002   0.000005   0.000006   0.000148   \n\n  feature_66 feature_67 feature_68 feature_69 feature_70 feature_71  \\\n0   0.000148        0.0        0.0        0.0        0.0        0.0   \n\n  feature_72 feature_73 feature_74 feature_75 feature_76 feature_77  \\\n0        0.0   0.009978   0.009978   0.001646   0.001646   0.000374   \n\n  feature_78 responder_0_lag_1 responder_1_lag_1 responder_2_lag_1  \\\n0   0.000374          0.018598          0.018598          0.018598   \n\n  responder_3_lag_1 responder_4_lag_1 responder_5_lag_1 responder_6_lag_1  \\\n0          0.018598          0.018598          0.018598          0.018598   \n\n  responder_7_lag_1 responder_8_lag_1 responder_6 weight symbol_id time_id  \n0          0.018598          0.018598         0.0    0.0       0.0     0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>feature_06</th>\n      <th>feature_07</th>\n      <th>feature_08</th>\n      <th>feature_09</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>feature_12</th>\n      <th>feature_13</th>\n      <th>feature_14</th>\n      <th>feature_15</th>\n      <th>feature_16</th>\n      <th>feature_17</th>\n      <th>feature_18</th>\n      <th>feature_19</th>\n      <th>feature_20</th>\n      <th>feature_21</th>\n      <th>feature_22</th>\n      <th>feature_23</th>\n      <th>feature_24</th>\n      <th>feature_25</th>\n      <th>feature_26</th>\n      <th>feature_27</th>\n      <th>feature_28</th>\n      <th>feature_29</th>\n      <th>feature_30</th>\n      <th>feature_31</th>\n      <th>feature_32</th>\n      <th>feature_33</th>\n      <th>feature_34</th>\n      <th>feature_35</th>\n      <th>feature_36</th>\n      <th>feature_37</th>\n      <th>feature_38</th>\n      <th>feature_39</th>\n      <th>feature_40</th>\n      <th>feature_41</th>\n      <th>feature_42</th>\n      <th>feature_43</th>\n      <th>feature_44</th>\n      <th>feature_45</th>\n      <th>feature_46</th>\n      <th>feature_47</th>\n      <th>feature_48</th>\n      <th>feature_49</th>\n      <th>feature_50</th>\n      <th>feature_51</th>\n      <th>feature_52</th>\n      <th>feature_53</th>\n      <th>feature_54</th>\n      <th>feature_55</th>\n      <th>feature_56</th>\n      <th>feature_57</th>\n      <th>feature_58</th>\n      <th>feature_59</th>\n      <th>feature_60</th>\n      <th>feature_61</th>\n      <th>feature_62</th>\n      <th>feature_63</th>\n      <th>feature_64</th>\n      <th>feature_65</th>\n      <th>feature_66</th>\n      <th>feature_67</th>\n      <th>feature_68</th>\n      <th>feature_69</th>\n      <th>feature_70</th>\n      <th>feature_71</th>\n      <th>feature_72</th>\n      <th>feature_73</th>\n      <th>feature_74</th>\n      <th>feature_75</th>\n      <th>feature_76</th>\n      <th>feature_77</th>\n      <th>feature_78</th>\n      <th>responder_0_lag_1</th>\n      <th>responder_1_lag_1</th>\n      <th>responder_2_lag_1</th>\n      <th>responder_3_lag_1</th>\n      <th>responder_4_lag_1</th>\n      <th>responder_5_lag_1</th>\n      <th>responder_6_lag_1</th>\n      <th>responder_7_lag_1</th>\n      <th>responder_8_lag_1</th>\n      <th>responder_6</th>\n      <th>weight</th>\n      <th>symbol_id</th>\n      <th>time_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.013187</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.024793</td>\n      <td>5.427434e-08</td>\n      <td>0.004132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001576</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001576</td>\n      <td>0.001576</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001576</td>\n      <td>0.009858</td>\n      <td>0.009858</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.070248</td>\n      <td>2.170974e-07</td>\n      <td>0.018595</td>\n      <td>0.070248</td>\n      <td>2.170974e-07</td>\n      <td>0.018595</td>\n      <td>0.000148</td>\n      <td>0.000148</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.070248</td>\n      <td>0.0</td>\n      <td>0.018595</td>\n      <td>0.070248</td>\n      <td>0.0</td>\n      <td>0.018595</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.009858</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00002</td>\n      <td>0.000005</td>\n      <td>0.000006</td>\n      <td>0.000148</td>\n      <td>0.000148</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.009978</td>\n      <td>0.009978</td>\n      <td>0.001646</td>\n      <td>0.001646</td>\n      <td>0.000374</td>\n      <td>0.000374</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.018598</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# fill na\ntrain_numpy = np.nan_to_num(train_numpy,nan=0)\nvalid_numpy = np.nan_to_num(valid_numpy,nan=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:18:59.534656Z","iopub.execute_input":"2024-12-30T07:18:59.535045Z","iopub.status.idle":"2024-12-30T07:19:26.241013Z","shell.execute_reply.started":"2024-12-30T07:18:59.535004Z","shell.execute_reply":"2024-12-30T07:19:26.240047Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"%%time\n\n# y_valid_data = y_valid.collect().to_numpy().squeeze(-1)\n# w_valid_data = w_valid.collect().to_numpy().squeeze(-1)\n\ntrain_data_tensor = torch.tensor(train_numpy, dtype=torch.float32)\nvalid_data_tensor = torch.tensor(valid_numpy, dtype=torch.float32)\n\ntrain_ds = TensorDataset(train_data_tensor)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=4, pin_memory=True, shuffle=True)\n\nvalid_ds = TensorDataset(valid_data_tensor)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=4, pin_memory=True, shuffle=False)\n\n# valid_data2_tensor = torch.tensor(valid_data_2.collect().to_numpy(), dtype=torch.float32)\n# valid2_ds = TensorDataset(valid_data2_tensor)\n# valid2_dl = DataLoader(valid2_ds, batch_size=batch_size, num_workers=4, pin_memory=True, shuffle=False)\n\nall_data = False\nif all_data:\n    train_ds = ConcatDataset([train_ds, valid_ds])\n    train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=4, pin_memory=True, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:26.242101Z","iopub.execute_input":"2024-12-30T07:19:26.242372Z","iopub.status.idle":"2024-12-30T07:19:29.459444Z","shell.execute_reply.started":"2024-12-30T07:19:26.242346Z","shell.execute_reply":"2024-12-30T07:19:29.458538Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 1.86 s, sys: 4.51 s, total: 6.36 s\nWall time: 3.21 s\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"del train_numpy,valid_numpy\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:29.460544Z","iopub.execute_input":"2024-12-30T07:19:29.460808Z","iopub.status.idle":"2024-12-30T07:19:29.720540Z","shell.execute_reply.started":"2024-12-30T07:19:29.460782Z","shell.execute_reply":"2024-12-30T07:19:29.719655Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"n_cont_features = 85\n# n_cont_features = 89\nn_cat_features = 4\nn_classes = None\n# cat_cardinalities = [83, 13, 540, 40]\ncat_cardinalities = [23, 10, 32, 40]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:29.721639Z","iopub.execute_input":"2024-12-30T07:19:29.722052Z","iopub.status.idle":"2024-12-30T07:19:29.734772Z","shell.execute_reply.started":"2024-12-30T07:19:29.722004Z","shell.execute_reply":"2024-12-30T07:19:29.733941Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## TabM Model","metadata":{}},{"cell_type":"code","source":"class LogCoshLoss(nn.Module):\n    def __init__(self):\n        super(LogCoshLoss, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        loss = torch.log(torch.cosh(y_pred - y_true))\n        return torch.mean(loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:29.735780Z","iopub.execute_input":"2024-12-30T07:19:29.736043Z","iopub.status.idle":"2024-12-30T07:19:29.744722Z","shell.execute_reply.started":"2024-12-30T07:19:29.736018Z","shell.execute_reply":"2024-12-30T07:19:29.744093Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"%%time\n\n# TabM\narch_type = 'tabm'\nbins = None\n\n# TabM-mini with the piecewise-linear embeddings.\n# arch_type = 'tabm-mini'\n# bins_input = train_data_tensor[:, :-4][:, [col for col in range(train_data_tensor[:, :-4].shape[1]) if col not in [9, 10, 11]]]\n# bins = compute_bins(bins_input[torch.randperm(len(bins_input))[:1000000]], ...)\n\n# del bins_input\n# gc.collect()\n\nk = 16 # 集成输出的数量\nmodel = Model(\n    n_num_features=n_cont_features,\n    cat_cardinalities=cat_cardinalities,\n    n_classes=n_classes,\n    backbone={\n        'type': 'MLP',\n        'n_blocks': 3 ,\n        'd_block': 256,\n        'dropout': 0.15,\n    },\n    bins=bins,\n    # num_embeddings=(\n    #     None\n    #     if bins is None\n    #     else {\n    #         'type': 'PiecewiseLinearEmbeddings',\n    #         'd_embedding': 16,\n    #         'activation': True,\n    #         'version': 'B',\n    #     }\n    # ),\n    num_embeddings=(\n        None\n        # {\n        #     'type': 'PeriodicEmbeddings',\n        #     'd_embedding': 16,\n        #     'lite':True,\n        # }\n    ),\n    arch_type=arch_type,\n    k=k,\n).to(device)\n\noptimizer = torch.optim.AdamW(\n    # Instead of model.parameters(),\n    make_parameter_groups(model),\n    lr=5e-4,\n    weight_decay=1e-4 ,\n)\n\n# loss_fn = nn.MSELoss()\nclass R2Loss(nn.Module):\n    def __init__(self):\n        super(R2Loss, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        mse_loss = torch.sum((y_pred - y_true) ** 2)\n        var_y = torch.sum(y_true ** 2)\n        loss = mse_loss / (var_y + 1e-38)\n        return loss\n\n# loss_fn = nn.HuberLoss(delta=0.2)\n# loss_fn = R2Loss()\nloss_fn = torch.nn.MSELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:29.745782Z","iopub.execute_input":"2024-12-30T07:19:29.746191Z","iopub.status.idle":"2024-12-30T07:19:31.033094Z","shell.execute_reply.started":"2024-12-30T07:19:29.746156Z","shell.execute_reply":"2024-12-30T07:19:31.032244Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 488 ms, sys: 225 ms, total: 713 ms\nWall time: 1.28 s\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"timer = delu.tools.Timer()\npatience = 5\nearly_stopping = delu.tools.EarlyStopping(patience, mode=\"max\")\nbest = {\n    \"val\": -math.inf,\n    \"epoch\": -1,\n}\ntimer.run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:31.034089Z","iopub.execute_input":"2024-12-30T07:19:31.034431Z","iopub.status.idle":"2024-12-30T07:19:31.038799Z","shell.execute_reply.started":"2024-12-30T07:19:31.034406Z","shell.execute_reply":"2024-12-30T07:19:31.037931Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def r2_val(y_true, y_pred, sample_weight):\n    residuals = sample_weight * (y_true - y_pred) ** 2\n    weighted_residual_sum = np.sum(residuals)\n\n    # Calculate weighted sum of squared true values (denominator)\n    weighted_true_sum = np.sum(sample_weight * (y_true) ** 2)\n\n    # Calculate weighted R2\n    r2 = 1 - weighted_residual_sum / weighted_true_sum\n\n    return r2\n\nfor epoch in range(num_epochs):\n    model.train()\n\n    # Training\n    train_pred_list = []\n    with tqdm(train_dl, total=len(train_dl), leave=True) as phar:\n        for train_tensor in phar:\n            optimizer.zero_grad()\n            X_input = train_tensor[0][:, :-4].to(device)\n            y_input = train_tensor[0][:, -4].to(device)\n            w_input = train_tensor[0][:, -3].to(device)\n\n            \n            symbol_input = train_tensor[0][:, -2].to(device)\n            time_input = train_tensor[0][:, -1].to(device)\n                \n            x_cont_input = X_input[:, [col for col in range(X_input.shape[1]) if col not in [9, 10, 11]]]\n            x_cont_input = x_cont_input + torch.randn_like(x_cont_input) * 0.035\n            \n            x_cat_input = X_input[:, [9, 10, 11]]\n            # x_cat_input = (torch.concat([x_cat_input, symbol_input.unsqueeze(-1), time_input.unsqueeze(-1)], axis=1)).to(torch.int64)\n            x_cat_input = (torch.concat([x_cat_input, symbol_input.unsqueeze(-1)], axis=1)).to(torch.int64)\n\n            \n\n            output = model(x_cont_input, x_cat_input).squeeze(-1)\n            loss = loss_fn(output.flatten(0, 1), y_input.repeat_interleave(k))\n\n            train_pred_list.append((output.mean(1), y_input, w_input))\n        \n            loss.backward()\n            optimizer.step()\n\n            phar.set_postfix(\n                OrderedDict(\n                    epoch=f'{epoch+1}/{num_epochs}',\n                    loss=f'{loss.item():.6f}',\n                    lr=f'{optimizer.param_groups[0][\"lr\"]:.3e}'\n                )\n            )\n            phar.update(1)\n\n    weights_train = torch.cat([x[2] for x in train_pred_list]).cpu().numpy()\n    y_train = torch.cat([x[1] for x in train_pred_list]).cpu().numpy()\n    prob_train = torch.cat([x[0] for x in train_pred_list]).detach().cpu().numpy()\n    train_r2 = r2_val(y_train, prob_train, weights_train)\n    \n    \n    model.eval()\n    valid_loss_list = []\n    valid_pred_list = []\n    for valid_tensor in tqdm(valid_dl):\n        X_valid = valid_tensor[0][:, :-4].to(device)\n        y_valid = valid_tensor[0][:, -4].to(device)\n        w_valid = valid_tensor[0][:, -3].to(device)\n        symbol_valid = valid_tensor[0][:, -2].to(device)\n        time_valid = valid_tensor[0][:, -1].to(device)\n        \n        x_cont_valid = X_valid[:, [col for col in range(X_valid.shape[1]) if col not in [9, 10, 11]]]\n        x_cont_valid = x_cont_valid + torch.randn_like(x_cont_valid) * 0.035\n        \n        x_cat_valid = X_valid[:, [9, 10, 11]]\n        # x_cat_valid = (torch.concat([x_cat_valid, symbol_valid.unsqueeze(-1),time_valid.unsqueeze(-1)], axis=1)).to(torch.int64)\n        x_cat_valid = (torch.concat([x_cat_valid, symbol_valid.unsqueeze(-1)], axis=1)).to(torch.int64)\n\n        with torch.no_grad():\n            y_pred = model(x_cont_valid, x_cat_valid).squeeze(-1)\n    \n        # val_loss = loss_fn(y_pred.squeeze(-1).squeeze(-1).cpu().detach(), y_valid)\n        # print(y_pred.flatten(0, 1),y_valid.repeat_interleave(k))\n        val_loss = loss_fn(y_pred.flatten(0, 1), y_valid.repeat_interleave(k))\n        valid_loss_list.append(val_loss)\n        valid_pred_list.append((y_pred.mean(1), y_valid, w_valid))\n    \n    valid_loss_mean = sum(valid_loss_list) / len(valid_loss_list)\n    # val_r2 = r2_score(y_valid_data, torch.cat(valid_pred_list).numpy(), sample_weight=w_valid_data)\n\n    weights_eval = torch.cat([x[2] for x in valid_pred_list]).cpu().numpy()\n    y_eval = torch.cat([x[1] for x in valid_pred_list]).cpu().numpy()\n    prob_eval = torch.cat([x[0] for x in valid_pred_list]).cpu().numpy()\n    val_r2 = r2_val(y_eval, prob_eval, weights_eval)\n\n\n    \n    print(f\"Epoch {epoch + 1}: train_r2 = {train_r2:.6f}, val_loss_mean={valid_loss_mean:.6f}, val_r2={val_r2:.6f}, [time] {timer}\")\n\n\n    \n    \n    \n    if val_r2 > best[\"val\"]:\n        print(\"🌸 New best epoch! 🌸\")\n        best = {\"val\": val_r2, \"epoch\": epoch}\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'r2': val_r2,\n        }\n        torch.save(checkpoint, f'epoch{epoch}_r2_{val_r2}.pt')\n    print()\n    \n    early_stopping.update(val_r2)\n    if early_stopping.should_stop():\n        print(\"Early stop\")\n        break\n\n\ncheckpoint = {\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    # 'r2': val_r2,\n}\n\ntorch.save(checkpoint, f'last_tabm.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T07:19:31.039933Z","iopub.execute_input":"2024-12-30T07:19:31.040230Z","execution_failed":"2024-12-30T07:22:52.729Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2250/2250 [02:33<00:00, 14.70it/s, epoch=1/30, loss=0.720350, lr=5.000e-04]\n100%|██████████| 450/450 [00:18<00:00, 24.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: train_r2 = 0.018012, val_loss_mean=0.641858, val_r2=0.007528, [time] 0:02:52.135034\n🌸 New best epoch! 🌸\n\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 409/2250 [00:29<02:06, 14.50it/s, epoch=2/30, loss=0.738875, lr=5.000e-04]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":10253875,"sourceType":"datasetVersion","datasetId":6297065},{"sourceId":10345067,"sourceType":"datasetVersion","datasetId":6406100},{"sourceId":215559969,"sourceType":"kernelVersion"},{"sourceId":215614744,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tab-transformer-pytorch -q --no-index --find-links=/kaggle/input/jane-street-import/tab-transformer-pytorch\n!pip install hyper_connections -q --no-index --find-links=/kaggle/input/jane-street-import/hyper_connections","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:32.886370Z","iopub.execute_input":"2025-01-02T08:49:32.886659Z","iopub.status.idle":"2025-01-02T08:49:40.705893Z","shell.execute_reply.started":"2025-01-02T08:49:32.886628Z","shell.execute_reply":"2025-01-02T08:49:40.704834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os,gc\nimport pickle\nimport polars as pl\nimport numpy as np\nimport pandas as pd\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:40.706985Z","iopub.execute_input":"2025-01-02T08:49:40.707341Z","iopub.status.idle":"2025-01-02T08:49:41.257791Z","shell.execute_reply.started":"2025-01-02T08:49:40.707307Z","shell.execute_reply":"2025-01-02T08:49:41.257159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CONFIG():\n    def __init__(self):\n        self.train_data_path = '/kaggle/input/data-create-create-lags/training.parquet'\n        self.valid_data_path = '/kaggle/input/data-create-create-lags/validation.parquet'\n        self.feature_names = [f\"feature_{i:02d}\" for i in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n        self.label_name = 'responder_6'\n        self.weight_name = 'weight'\n        self.feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n        self.feature_cont = [item for item in self.feature_names if item not in self.feature_cat]\n        self.train_start_dt = 1100\nmy_config = CONFIG()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:41.258592Z","iopub.execute_input":"2025-01-02T08:49:41.259013Z","iopub.status.idle":"2025-01-02T08:49:41.263899Z","shell.execute_reply.started":"2025-01-02T08:49:41.258982Z","shell.execute_reply":"2025-01-02T08:49:41.263140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_stats = joblib.load('/kaggle/input/my-own-js/data_stats.pkl')\nmeans = data_stats['mean']\nstds = data_stats['std']\n\ndef standardize(df, feature_cols, means, stds):\n    return df.with_columns([\n        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n    ])\n\ncategory_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n}\n\ndef encode_column(df, column, mapping):\n    def encode_category(category):\n        return mapping.get(category, -1)  \n    \n    return df.with_columns(\n        pl.col(column).map_elements(encode_category, return_dtype=pl.Int16).alias(column)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:41.265644Z","iopub.execute_input":"2025-01-02T08:49:41.265882Z","iopub.status.idle":"2025-01-02T08:49:41.285962Z","shell.execute_reply.started":"2025-01-02T08:49:41.265852Z","shell.execute_reply":"2025-01-02T08:49:41.285163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport warnings\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# import pytorch_lightning as pl\nfrom pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom tab_transformer_pytorch import FTTransformer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:41.287002Z","iopub.execute_input":"2025-01-02T08:49:41.287315Z","iopub.status.idle":"2025-01-02T08:49:49.548177Z","shell.execute_reply.started":"2025-01-02T08:49:41.287276Z","shell.execute_reply":"2025-01-02T08:49:49.547302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class R2Loss(nn.Module):\n    def __init__(self):\n        super(R2Loss, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        mse_loss = torch.sum((y_pred - y_true) ** 2)\n        var_y = torch.sum(y_true ** 2)\n        loss = mse_loss / (var_y + 1e-38)\n        return loss\n\n# Custom R2 metric for validation\ndef r2_val(y_true, y_pred, sample_weight):\n    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n    return r2\n\n\nclass FTTransformerModel(LightningModule):\n    def __init__(self, n_cont_features, cat_cardinalities, lr, weight_decay):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = FTTransformer(\n                categories = cat_cardinalities,      # tuple containing the number of unique values within each category\n                num_continuous = n_cont_features,                # number of continuous values\n                dim = 4,                           # dimension, paper set at 32\n                dim_out = 1,                        # binary prediction, but could be anything\n                depth = 3,                          # depth, paper recommended 6\n                heads = 2,                          # heads, paper recommends 8\n                attn_dropout = 0.2,                 # post-attention dropout\n                ff_dropout = 0.2                    # feed forward dropout\n            )\n        self.lr = lr\n        self.weight_decay = weight_decay\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        # self.loss_fn = F.mse_loss()\n        # self.loss_fn = R2Loss()\n        # self.loss_fn = weighted_mse_loss\n\n    def forward(self, x_cont, x_cat):\n        return self.model(x_cat, x_cont).squeeze(-1)\n        # return self.model(x_cont, x_cat).squeeze(-1)\n\n    def training_step(self, batch):\n        x_cont, x_cat, y, w = batch\n        # x_cont = x_cont + torch.randn_like(x_cont) * 0.01\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        \n        loss = F.mse_loss(y_hat, y, reduction='none') * w  #\n        loss = loss.mean()\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.training_step_outputs.append((y_hat , y, w))\n        return loss\n\n    def validation_step(self, batch):\n        x_cont, x_cat, y, w = batch\n        # x_cont = x_cont + torch.randn_like(x_cont)\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        loss = F.mse_loss(y_hat, y, reduction='none') * w  #\n        loss = loss.mean()\n        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.validation_step_outputs.append((y_hat , y, w))\n        return loss\n\n    def on_validation_epoch_end(self):\n        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n        if self.trainer.sanity_checking:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n        else:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n            # r2_val\n            val_r_square = r2_val(y, prob, weights)\n            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.validation_step_outputs.clear()\n\n    # def my_configure_optimizers(self):\n    #     optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n    #                                                            verbose=True)\n    #     return {\n    #         'optimizer': optimizer,\n    #         'lr_scheduler': {\n    #             'scheduler': scheduler,\n    #             'monitor': 'val_r_square',\n    #         }\n    #     }\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n                                                               verbose=True)\n        return {\n            'optimizer': optimizer,\n            'lr_scheduler': {\n                'scheduler': scheduler,\n                'monitor': 'val_loss',\n            }\n        }\n\n    def on_train_epoch_end(self):\n        if self.trainer.sanity_checking:\n            return\n\n        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n        # r2_training\n        train_r_square = r2_val(y, prob, weights)\n        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.training_step_outputs.clear()\n\n        epoch = self.trainer.current_epoch\n        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n        print(f\"Epoch {epoch}: {formatted_metrics}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:49.549075Z","iopub.execute_input":"2025-01-02T08:49:49.549381Z","iopub.status.idle":"2025-01-02T08:49:49.572216Z","shell.execute_reply.started":"2025-01-02T08:49:49.549353Z","shell.execute_reply":"2025-01-02T08:49:49.571147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel_path = '/kaggle/input/ft-transformer-model/nn_0.model.ckpt'\nmodel = FTTransformerModel.load_from_checkpoint(model_path).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:49.573265Z","iopub.execute_input":"2025-01-02T08:49:49.573593Z","iopub.status.idle":"2025-01-02T08:49:50.190949Z","shell.execute_reply.started":"2025-01-02T08:49:49.573560Z","shell.execute_reply":"2025-01-02T08:49:50.190081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\nlags_last : pl.DataFrame | None = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    global lags_\n    global lags_last\n\n    if lags is not None:\n        lags_ = lags\n    \n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n        \n    for col in my_config.feature_cat:\n        test = encode_column(test, col, category_mappings[col])\n    \n    if lags is not None:\n        lags_ = lags\n        lags_last = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n    \n    id_column_types = {\n        'date_id': pl.Int32,\n        'time_id': pl.Int32,\n        'symbol_id': pl.Int32\n    }\n    test = test.cast(id_column_types)\n    lags_last = lags_last.cast(id_column_types)\n\n    test = test.join(lags_last, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n\n    # 先标准化在fillna(0)\n    test = standardize(test, my_config.feature_cont, means, stds)\n\n    test = test.with_columns([\n        pl.col(col).fill_null(0).alias(col) for col in my_config.feature_names\n    ])\n    \n    # X_test = test[my_config.feature_names].to_numpy()\n    # X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n    # X_cat = X_test_tensor[:, [9, 10, 11]]\n    # X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n    # # X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n    # X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n\n    X_cont = test[my_config.feature_cont].to_numpy()\n    X_cont = torch.tensor(X_cont, dtype=torch.float32).to(device)\n    X_cat = test[my_config.feature_cat].to_numpy()\n    X_cat = torch.tensor(X_cat, dtype=torch.int64).to(device)\n    # print(X_cont.shape,X_cat.shape)\n    model.eval()\n    with torch.no_grad():\n        outputs = model(X_cont, X_cat)\n        # Assuming the model outputs a tensor of shape (batch_size, 1)\n        preds = outputs.squeeze(-1).cpu().numpy()\n        # print(preds.shape)\n        # preds = preds.mean(1)\n    \n    predictions = \\\n    test.select('row_id').\\\n    with_columns(\n        pl.Series(\n            name   = 'responder_6', \n            values = np.clip(preds, a_min = -5, a_max = 5),\n            dtype  = pl.Float64,\n        )\n    )\n\n\n    # The predict function must return a DataFrame\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    # with columns 'row_id', 'responer_6'\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    # and as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:50.191896Z","iopub.execute_input":"2025-01-02T08:49:50.192188Z","iopub.status.idle":"2025-01-02T08:49:50.201244Z","shell.execute_reply.started":"2025-01-02T08:49:50.192166Z","shell.execute_reply":"2025-01-02T08:49:50.200141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.jane_street_inference_server\n\ninference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:49:50.202820Z","iopub.execute_input":"2025-01-02T08:49:50.203125Z","iopub.status.idle":"2025-01-02T08:49:51.188388Z","shell.execute_reply.started":"2025-01-02T08:49:50.203076Z","shell.execute_reply":"2025-01-02T08:49:51.187610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}